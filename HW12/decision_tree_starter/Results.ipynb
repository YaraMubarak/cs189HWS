{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "%matplotlib notebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART A "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#     @staticmethod\n",
    "#     def information_gain(X, y, thresh):\n",
    "#         X0,y0,X1,y1 = split(X,y, thresh) \n",
    "#         def g(y): \n",
    "#             pyk_2 = 0 \n",
    "#             for i in range(2): \n",
    "#                 try: \n",
    "#                     pyeqk = len(y[y == i])/float(len(y)) \n",
    "#                     pyk_2 = pyeqk**2 \n",
    "#                 except ZeroDivisionError: \n",
    "#                     pyeqk = 0 \n",
    "#             return 1 - pyk_2 \n",
    "        \n",
    "#         return len(X0)*g(y0)/float(len(X)) + len(X1)*g(y1)/float(len(X))\n",
    "\n",
    "#     @staticmethod\n",
    "#     def gini_impurity(X, y, thresh):\n",
    "#         X0,y0,X1,y1 = split(X,y, thresh) \n",
    "        \n",
    "#         def h(y) : \n",
    "#             hy = 0 \n",
    "#             for i in range(2) : \n",
    "#                 try : \n",
    "#                     pyeqk = len(y[y == i])/float(len(y)) \n",
    "#                     hy = hy - pyeqk*np.log(pyeqk)\n",
    "#                 except ZeroDivisionError : \n",
    "#                     pyeqk = 0 \n",
    "                \n",
    "#             return hy \n",
    "        \n",
    "#         return len(X0)*h(y0)/float(len(X)) + len(X1)*h(y1)/float(len(X)) \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART C \n",
    "<img src=\"tree_part_c.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART D (Bagged Trees) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# class BaggedTrees(BaseEstimator, ClassifierMixin):\n",
    "#     def __init__(self, params=None, n=200):\n",
    "\n",
    "#         if params is None:\n",
    "#             params = {}\n",
    "#         self.params = params\n",
    "#         self.n = n\n",
    "#         self.decision_trees = [\n",
    "#             sklearn.tree.DecisionTreeClassifier(random_state=i, **self.params)\n",
    "#             for i in range(self.n)\n",
    "#         ]\n",
    "\n",
    "#     def fit(self, X, y):\n",
    "#     \tself.mask = []\n",
    "#     \tfor tree in self.decision_trees: \n",
    "#     \t\tmask = np.random.randint(0, high = len(X), size= len(X)) \n",
    "#     \t\tXsampling = X[mask,:]\n",
    "#     \t\tysampling = y[mask]\n",
    "#     \t\ttree.fit(Xsampling,ysampling)\n",
    "#     \t\tself.mask.append(mask)\n",
    "\n",
    "\n",
    "\n",
    "#     def predict(self, X):\n",
    "#     \tpreds = [] \n",
    "#     \tfor tree in self.decision_trees: \n",
    "#     \t\tpreds.append(tree.predict(X))\n",
    "#     \treturn stats.mode(np.array(preds), axis = 0 )[0].reshape(len(X))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART F (Random Forest ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# class RandomForest(BaggedTrees):\n",
    "#     def __init__(self, params=None, n=200, m=2):\n",
    "#     \tsuper().__init__(params = params , n = n ) \n",
    "#     \tself.m = m \n",
    "\n",
    "#     def fit(self, X,y):\n",
    "#     \tself.mask = []\n",
    "#     \tself.features = [] \n",
    "#     \tfor tree in self.decision_trees: \n",
    "#         \tmask = np.random.randint(0, high = len(X), size= len(X)) \n",
    "#         \tfeatures = np.random.choice( X.shape[1], size = self.m )\n",
    "#         \tXsampling = X[mask,:]\n",
    "#         \tXsampling = Xsampling[:,features]\n",
    "#         \tysampling = y[mask]\n",
    "#         \ttree.fit(Xsampling,ysampling)\n",
    "#         \tself.mask.append(mask)\n",
    "#         \tself.features.append(features)\n",
    "#     def predict(self,X):\n",
    "#     \tpreds = [] \n",
    "#     \tk = 0 \n",
    "#     \tfor tree in self.decision_trees: \n",
    "#     \t\tpreds.append(tree.predict(X[:,self.features[k]]))\n",
    "#     \treturn stats.mode(np.array(preds), axis = 0 )[0].reshape(len(X))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART H (AdaBoost) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# class BoostedRandomForest(RandomForest):\n",
    "#     def fit(self, X, y ):\n",
    "#         self.w = np.ones(X.shape[0]) / X.shape[0]  # Weights on data\n",
    "#         self.a = np.zeros(self.n)  # Weights on decision trees\n",
    "#         k = 0 \n",
    "#         self.features = [] \n",
    "#         for tree in self.decision_trees: \n",
    "#         \tmask = np.random.randint(0, high = len(X), size= len(X)) \n",
    "#         \tfeatures = np.random.choice(X.shape[1], size = self.m )\n",
    "#         \tXsampling = X[mask,:]\n",
    "#         \tXsampling = Xsampling[:,features]\n",
    "#         \tysampling = y[mask]\n",
    "#         \ttree.fit(Xsampling,ysampling)\n",
    "#         \tself.features.append(features)\n",
    "\n",
    "#         \tej = 0 \n",
    "#         \tfor j in range(len(Xsampling)):\n",
    "#         \t\tej = checkXY(Xsampling[j,:], ysampling[j], tree )*self.w[j] + ej \n",
    "\n",
    "#         \tej = ej/float(sum(self.w))\n",
    "\n",
    "#         \tself.a[k] = 0.5*np.log((1-ej)/float(ej))\n",
    "\n",
    "#         \tfor i in range(len(Xsampling)):\n",
    "#         \t\tif checkXY(Xsampling[i,:],ysampling[i], tree) > 0.5 : \n",
    "#         \t\t\tself.w[i] = self.w[i]*np.exp(self.a[k])\n",
    "#         \t\telse : \n",
    "#         \t\t\tself.w[i] = self.w[i]*np.exp(-self.a[k])\n",
    "#         \tk = k + 1 \n",
    "        \n",
    "\n",
    "#     def predict(self, X):\n",
    "#         classes = list(set(y)) \n",
    "#         preds_tot = [] \n",
    "#         for i in range(len(X)):\n",
    "#         \tpreds = [] \n",
    "#         \tfor c in classes : \n",
    "#         \t\tzj = 0 \n",
    "#         \t\tk = 0 \n",
    "#         \t\tfor tree in self.decision_trees: \n",
    "#         \t\t\tXcheck = X[:,self.features[k]]\n",
    "#         \t\t\tXcheck = Xcheck[i,:]\n",
    "#         \t\t\tzj = zj + self.a[k]*checkXY(Xcheck, c, tree)\n",
    "#         \t\t\tk = k + 1 \n",
    "#         \t\tpreds.append(zj)\n",
    "#        \t\tpreds_tot.append(classes[np.argmax(preds)])\n",
    "#        \treturn preds_tot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part J (Results) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TITANIC : \n",
    "# accuracy = [kfold1, kfold2, kfold3, avg_training]\n",
    "\n",
    "# DecisionTree\n",
    "# [0.5993975903614458, 0.63855421686746983, 0.60240963855421692, 0.61369315342328834]\n",
    "# BaggedTrees\n",
    "# accuracy = [kfold1, kfold2, kfold3, avg_training]\n",
    "# [0.79518072289156627, 0.76204819277108438, 0.77710843373493976, 0.97801099450274853]\n",
    "# RandomForest\n",
    "# accuracy = [kfold1, kfold2, kfold3, avg_training]\n",
    "# [0.5993975903614458, 0.4006024096385542, 0.60240963855421692, 0.58020989505247378]\n",
    "# Adaboost\n",
    "# [0.21686746987951808, 0.63855421686746983, 0.21385542168674698, 0.24837581209395301]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# SPAM\n",
    "\n",
    "# DecisionTree\n",
    "# accuracy = [kfold1, kfold2, kfold3, avg_training]\n",
    "# [0.5993975903614458, 0.63855421686746983, 0.60240963855421692, 0.61369315342328834]\n",
    "# BaggedTrees\n",
    "# accuracy = [kfold1, kfold2, kfold3, avg_training]\n",
    "# [0.78915662650602414, 0.76204819277108438, 0.77409638554216864, 0.97801099450274853]\n",
    "# RandomForest\n",
    "# accuracy = [kfold1, kfold2, kfold3, avg_training]\n",
    "# [0.5993975903614458, 0.6506024096385542, 0.61144578313253017, 0.62868565717141422]\n",
    "# Adaboost\n",
    "# accuracy = [kfold1, kfold2, kfold3, avg_training]\n",
    "# [0.5993975903614458, 0.22289156626506024, 0.21987951807228914, 0.24887556221889059]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
